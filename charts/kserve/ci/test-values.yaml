# See https://github.com/helm/chart-testing/blob/main/doc/ct_install.md#synopsis
# This file is picked up by ct testing tool

# Default values for kserve PURELY FOR github action tests
# Memory and CPU resources for ClusterServingRuntimes
# scaled down drastically, DO NOT USE for production!

labels:
  common:
    environment: "test"

# Specify how inference service is deployed:
# - Serverless, use Knative
# - RawDeployment, use K8S Deployment
defaultDeploymentMode: Serverless

controller:
  image:
    registry: ""
    repository: kserve/kserve-controller
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "v0.8.0"

  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 100m
      memory: 128Mi

  nodeSelector: {}
  tolerations: []
  affinity: {}

ingress:
  ingressGateway: knative-serving/knative-ingress-gateway
  ingressService: istio-ingressgateway.istio-system-kserve.svc.cluster.local
  localGateway: knative-serving/knative-local-gateway
  localGatewayService: cluster-local-gateway.istio-system-kserve.svc.cluster.local
  ingressDomain: example.com
  ingressClassName: istio
  domainTemplate: "{{ .Name }}-{{ .Namespace }}.{{ .IngressDomain }}"

logger:
  image:
    registry: ""
    repository: kserve/agent
    tag: v0.8.0
  resources:
    requests:
      cpu: 50m
      memory: 100Mi
    limits:
      cpu: 1
      memory: 1Gi
  defaultUrl: http://default-broker

agent:
  image:
    registry: ""
    repository: kserve/agent
    tag: v0.8.0
  resources:
    requests:
      cpu: 50m
      memory: 100Mi
    limits:
      cpu: 1
      memory: 1Gi


batcher:
  image:
    registry: ""
    repository: kserve/agent
    tag: v0.8.0
  resources:
    requests:
      cpu: 50m
      memory: 1Gi
    limits:
      cpu: 1
      memory: 1Gi

storageInitializer:
  image:
    registry: ""
    repository: kserve/storage-initializer
    tag: v0.8.0
  resources:
    requests:
      cpu: 50m
      memory: 100Mi
    limits:
      cpu: 1
      memory: 1Gi

predictors:
  tensorflow:
    image: tensorflow/serving
    defaultImageVersion: 2.6.2
    defaultGpuImageVersion: 2.6.2-gpu
    defaultTimeout: "60"
    supportedFrameworks:
      - tensorflow
    multiModelServer: false
  onnx:
    image: mcr.microsoft.com/onnxruntime/server
    defaultImageVersion: v1.0.0
    supportedFrameworks:
      - onnx
    multiModelServer: false
  sklearn:
    v1:
      image: kserve/sklearnserver
      defaultImageVersion: v0.8.0
      supportedFrameworks:
        - sklearn
      multiModelServer: true
    v2:
      image: docker.io/seldonio/mlserver
      defaultImageVersion: 0.5.3
      supportedFrameworks:
        - sklearn
      multiModelServer: true
  xgboost:
    v1:
      image: kserve/xgbserver
      defaultImageVersion: v0.8.0
      supportedFrameworks:
        - xgboost
      multiModelServer: true
    v2:
      image: docker.io/seldonio/mlserver
      defaultImageVersion: 0.5.3
      supportedFrameworks:
        - xgboost
      multiModelServer: true
  pytorch:
    v1:
      image: kserve/torchserve-kfs
      defaultImageVersion: 0.5.3
      defaultGpuImageVersion: 0.5.3-gpu
      supportedFrameworks:
        - pytorch
      multiModelServer: false
    v2:
      image: kserve/torchserve-kfs
      defaultImageVersion: 0.5.3
      defaultGpuImageVersion: 0.5.3-gpu
      supportedFrameworks:
        - pytorch
      multiModelServer: false
  triton:
    image: nvcr.io/nvidia/tritonserver
    defaultImageVersion: 21.09-py3
    supportedFrameworks:
      - tensorrt
      - tensorflow
      - onnx
      - pytorch
    multiModelServer: true
  pmml:
    image: kserve/pmmlserver
    defaultImageVersion: v0.8.0
    supportedFrameworks:
      - pmml
    multiModelServer: false
  lightgbm:
    image: kserve/lgbserver
    defaultImageVersion: v0.8.0
    supportedFrameworks:
      - lightgbm
    multiModelServer: false
  paddle:
    image: kserve/paddleserver
    defaultImageVersion: v0.8.0
    supportedFrameworks:
      - paddle
    multiModelServer: false

clusterServingRuntimes:
  - name: kserve-lgbserver
    spec:
      containers:
        - args:
            - --model_name={{.Name}}
            - --model_dir=/mnt/models
            - --http_port=8080
            - --nthread=1
          image: kserve/lgbserver:v0.8.0
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: lightgbm
          version: "2"
  - name: kserve-mlserver
    spec:
      containers:
        - env:
            - name: MLSERVER_MODEL_IMPLEMENTATION
              value: "{{.Labels.modelClass}}"
            - name: MLSERVER_HTTP_PORT
              value: "8080"
            - name: MLSERVER_GRPC_PORT
              value: "9000"
            - name: MODELS_DIR
              value: /mnt/models
          image: docker.io/seldonio/mlserver:0.5.3
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - name: sklearn
          version: "0"
        - name: xgboost
          version: "1"
        - name: lightgbm
          version: "3"
        - autoSelect: true
          name: mlflow
          version: "1"
  - name: kserve-paddleserver
    spec:
      containers:
        - args:
            - --model_name={{.Name}}
            - --model_dir=/mnt/models
            - --http_port=8080
          image: kserve/paddleserver:v0.8.0
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: paddle
          version: "2"
  - name: kserve-pmmlserver
    spec:
      containers:
        - args:
            - --model_name={{.Name}}
            - --model_dir=/mnt/models
            - --http_port=8080
          image: kserve/pmmlserver:v0.8.0
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: pmml
          version: "3"
        - autoSelect: true
          name: pmml
          version: "4"
  - name: kserve-sklearnserver
    spec:
      containers:
        - args:
            - --model_name={{.Name}}
            - --model_dir=/mnt/models
            - --http_port=8080
          image: kserve/sklearnserver:v0.8.0
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: sklearn
          version: "1"
  - name: kserve-tensorflow-serving
    spec:
      containers:
        - args:
            - --model_name={{.Name}}
            - --port=9000
            - --rest_api_port=8080
            - --model_base_path=/mnt/models
            - --rest_api_timeout_in_ms=60000
          command:
            - /usr/bin/tensorflow_model_server
          image: tensorflow/serving:2.6.2
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: tensorflow
          version: "1"
        - autoSelect: true
          name: tensorflow
          version: "2"
  - name: kserve-torchserve
    spec:
      containers:
        - args:
            - torchserve
            - --start
            - --model-store=/mnt/models/model-store
            - --ts-config=/mnt/models/config/config.properties
          env:
            - name: TS_SERVICE_ENVELOPE
              value: "{{.Labels.serviceEnvelope}}"
          image: kserve/torchserve-kfs:0.5.3
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: pytorch
          version: "1"
  - name: kserve-tritonserver
    spec:
      containers:
        - args:
            - tritonserver
            - --model-store=/mnt/models
            - --grpc-port=9000
            - --http-port=8080
            - --allow-grpc=true
            - --allow-http=true
          image: nvcr.io/nvidia/tritonserver:21.09-py3
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - name: tensorrt
          version: "8"
        - name: tensorflow
          version: "1"
        - name: tensorflow
          version: "2"
        - autoSelect: true
          name: onnx
          version: "1"
        - name: pytorch
          version: "1"
        - autoSelect: true
          name: triton
          version: "2"
  - name: kserve-xgbserver
    spec:
      containers:
        - args:
            - --model_name={{.Name}}
            - --model_dir=/mnt/models
            - --http_port=8080
            - --nthread=1
          image: kserve/xgbserver:v0.8.0
          name: kserve-container
          resources:
            limits:
              cpu: 100m
              memory: 250Mi
            requests:
              cpu: 100m
              memory: 250Mi
      supportedModelFormats:
        - autoSelect: true
          name: xgboost
          version: "1"

###################################################################
# knativeServingIstio dependency configuration
# #################################################################
knativeServingIstio:
  enabled: true
  helmChart:
    chart: knative-serving-istio
    version: 1.3.8
    repository: "https://caraml-dev.github.io/helm-charts"
    release: knative-serving
    namespace: knative-serving
    createNamespace: true
  chartValues:

    config:
      istio:
        # NOTE: assumes istio edge proxies (*-gateway deployments) are deployed in istio-system-knative-serving-istio namespace
        gateway.{{ .Release.Namespace }}.knative-ingress-gateway: "istio-ingressgateway.istio-system-kserve.svc.cluster.local"
        local-gateway.{{ .Release.Namespace }}.knative-local-gateway: "cluster-local-gateway.istio-system-kserve.svc.cluster.local"

    controller:
      resources:
        requests:
          cpu: 50m
          memory: 512Mi
        limits:
          cpu: 100m
          memory: 512Mi

    webhook:
      resources:
        requests:
          cpu: 50m
          memory: 100Mi
        limits:
          cpu: 200m
          memory: 500Mi

    knativeServingCore:
      activator:
        resources:
          requests:
            cpu: 50m
            memory: 500Mi
          limits:
            cpu: 250m
            memory: 500Mi

      autoscaler:
        resources:
          requests:
            cpu: 50m
            memory: 500Mi
          limits:
            cpu: 250m
            memory: 500Mi

      controller:
        resources:
          requests:
            cpu: 50m
            memory: 500Mi
          limits:
            cpu: 250m
            memory: 500Mi

      domainMapping:
        resources:
          requests:
            cpu: 30m
            memory: 40Mi
          limits:
            cpu: 50m
            memory: 100Mi

      domainMappingWebhook:
        resources:
          requests:
            cpu: 50m
            memory: 100Mi
          limits:
            cpu: 250m
            memory: 500Mi

      webhook:
        resources:
          requests:
            cpu: 50m
            memory: 100Mi
          limits:
            cpu: 250m
            memory: 500Mi

      autoscalerHpa:
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 250m
            memory: 500Mi

    base:
      global:
        istioNamespace: "istio-system-kserve"

    istiod:
      helmChart:
        namespace: "istio-system-kserve"
      chartValues:
        global:
          istioNamespace: "istio-system-kserve"
        pilot:
          resources:
            requests:
              cpu: 50m
              memory: 512Mi
            limits:
              cpu: 200m
              memory: 1024Mi

    istioIngressGateway:
      helmChart:
        namespace: "istio-system-kserve"
      chartValues:
        global:
          istioNamespace: "istio-system-kserve"
        resources:
          requests:
            cpu: 50m
            memory: 512Mi
          limits:
            cpu: 200m
            memory: 512Mi

    clusterLocalGateway:
      helmChart:
        namespace: "istio-system-kserve"
      chartValues:
        global:
          istioNamespace: "istio-system-kserve"
        resources:
          requests:
            cpu: 50m
            memory: 512Mi
          limits:
            cpu: 200m
            memory: 512Mi

###################################################################
# Cert manager Base for Cert Manager CRDs
# #################################################################
certManagerBase:
  enabled: true

###################################################################
# Cert manager dependency
# #################################################################
# Use hyphen so chart name can be used as part of resource name
cert-manager:
  fullnameOverride: cert-manager
  enabled: true
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 20m
      memory: 64Mi
  startupapicheck:
    resources:
      requests:
        cpu: 10m
        memory: 32Mi
      limits:
        cpu: 20m
        memory: 64Mi
  webhook:
    resources:
      requests:
        cpu: 10m
        memory: 32Mi
      limits:
        cpu: 20m
        memory: 64Mi
  cainjector:
    resources:
      requests:
        cpu: 10m
        memory: 32Mi
      limits:
        cpu: 20m
        memory: 64Mi


  # NOTE: We do not enable crds because the crds are installed in separate helm chart
  # installCRDs: true
