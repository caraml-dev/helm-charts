global:
  protocol: http
deployment:
  image:
    pullPolicy: IfNotPresent
    registry: ghcr.io
    repository: caraml-dev/merlin
    tag: 0.28.0-1-g07b5aaa
  replicaCount: "2"
  # Additional labels to apply to the deployment
  labels: {}
  # Additional labels to apply to the merlin pods
  podLabels: {}
  resources:
    requests:
      cpu: "500m"
      memory: 1Gi
    limits:
      cpu: "1"
      memory: 1Gi
  # expects input structure as per specification https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#toleration-v1-core
  # for example:
  #   tolerations:
  #   - key: foo.bar.com/role
  #     operator: Equal
  #     value: master
  #     effect: NoSchedule
  tolerations: []

config:
  DeploymentLabelPrefix: "gojek.com/"
  Environment: dev
  Port: 8080
  LoggerDestinationURL: "http://yourDestinationLogger"
  Sentry:
    Enabled: false
    DSN: ""
  NewRelic:
    Enabled: false
    AppName: "merlin-api-dev"
    License: "newrelic-license-secret"
    IgnoreStatusCodes: [400,401,403,404,405,412]
  EnvironmentConfigPath: "environments.yaml"
  NumOfQueueWorkers: 2
  DbConfig:
    Host: localhost
    Port: 5432
    Database: merlin
    User: merlin
    Password: merlin
  ImageBuilderConfig:
    ClusterName: "test"
    BaseImages:
      3.7.*:
        ImageName: pyfunc-py37:v0.1.0
        DockerfilePath: "docker/Dockerfile"
        BuildContextURI: "git://github.com/gojek/merlin.git#refs/tags/v0.1"
        MainAppPath: /merlin-spark-app/main.py
    PredictionJobBaseImages:
      3.7.*:
        ImageName: pyspark-py37:v0.1.0
        DockerfilePath: "docker/app.Dockerfile"
        BuildContextURI: "git://github.com/gojek/merlin.git#refs/tags/v0.1"
        MainAppPath: /merlin-spark-app/main.py
    BuildNamespace: "mlp"
    DockerRegistry: "dockerRegistry"
    BuildTimeout: "30m"
    KanikoImage: "gcr.io/kaniko-project/executor:v1.6.0"
    Resources:
      Requests:
        CPU: "1"
        Memory: 512Mi
      Limits:
        CPU: "1"
        Memory: 1Gi
    Tolerations: []
    NodeSelectors: {}
    MaximumRetry: 3
    KanikoServiceAccount: "kaniko"
    Retention: "48h"
    K8sConfig: ""
    # Example json
    # '{
    #   "name": "dev-cluster",
    #   "cluster": {
    #     "server": "https://k8s.cluster",
    #     "certificate-authority-data": "some_cert_data"
    #   },
    #   "user": {
    #     "exec": {
    #       "apiVersion": "client.authentication.k8s.io/v1beta1",
    #       "args": [
    #         "--use_application_default_credentials"
    #       ],
    #       "command": "gke-gcloud-auth-plugin",
    #       "interactiveMode": "IfAvailable",
    #       "provideClusterInfo": true
    #     }
    #   }
    # }'
  AuthorizationConfig:
    AuthorizationEnabled: true
    AuthorizationServerURL: http://mlp-authorization-keto
    Caching:
      # -- Whether local in-memory caching of authorization responses should be enabled
      Enabled: false
      # -- Cache key expiry duration
      KeyExpirySeconds: 600
      # -- Cache clean up interval, after which expired keys are removed
      CacheCleanUpIntervalSeconds: 900
  MlpAPIConfig:
    APIHost: http://mlp.mlp:8080/v1
    # EncryptionKey must be specified using --set flag.
    EncryptionKey: secret-encryption
  FeatureToggleConfig:
    MonitoringConfig:
      MonitoringEnabled: false
      MonitoringBaseURL: ""
      MonitoringJobBaseURL: ""
    AlertConfig:
      # -- To enable/disable creation/modification of the alerts and dashboards for the deployed models via merlin.
      AlertEnabled: false
      GitlabConfig:
        BaseURL: https://gitlab.com/
        # Access token must be specified using --set flag.
        # Token:
        DashboardRepository: data-science/slo-specs
        DashboardBranch: master
        AlertRepository: lens/artillery/datascience
        AlertBranch: master
      WardenConfig:
        APIHost: ""
  StandardTransformerConfig:
    ImageName: merlin-transformer:1.0.0
    SimulationFeast:
      FeastRedisURL: online-serving-redis.feast.dev
      FeastBigtableURL: online-serving-bt.feast.dev
    FeastServingURLs:
      - Host: "online-serving-redis.feast.dev"
        Label: "Online Serving with Redis"
        Icon: "redis"
        SourceType: "REDIS"
      - Host: "online-serving-bigtable.feast.dev"
        Label: "Online Serving with BigTable"
        Icon: "bigtable"
        SourceType: "BIGTABLE"
    DefaultServingURL: online-serving-redis.feast.dev
#    ## Redis storage configuration for feast retrieval
#    FeastRedisConfig:
#      IsRedisCluster: true
#      IsUsingDirectStorage: false
#      ServingURL: "online-serving-redis.feast.dev"
#      RedisAddresses:
#        - 10.1.1.2
#        - 10.1.1.3
#      PoolSize: 5
#      MaxRetries: 0
#      ReadTimeout: "1s"
#      WriteTimeout: "1s"
#      IdleTimeout: "15s"
#      IdleCheckFrequency: "5s"
#      MinIdleConn: 2
#    ## Bigtable storage configuration for feast retrieval
#    FeastBigtableConfig:
#      ServingURL: "online-serving-bigtable.feast.dev"
#      IsUsingDirectStorage: false
#      Project: gcp-project
#      Instance: instance
#      AppProfile: default
#      PoolSize: 5
#      KeepAliveInterval: 2m
#      KeepAliveTimeout: 1m
    BigtableCredential:
    FeastServingKeepAlive:
      Enabled: false
      Time: 60s
      Timeout: 5s
    DefaultFeastSource: BIGTABLE  # or 2
    FeastCoreURL: core.feast.dev
    FeastCoreAuthAudience: core.feast.dev
    EnableAuth: false
    Jaeger:
      AgentHost: localhost
      AgentPort: 6831
      SamplerType: const
      SamplerParam: 1
      Disabled: false
    Kafka:
      Brokers: "kafka-brokers"
      MaxMessageSizeBytes: "1048588"
  PyfuncGRPCOptions: "{}"
  EnvironmentConfigs:
    - Name: "id-dev"
      IsDefault: true
      Cluster: "test"
      Region: "id"
      GcpProject: "gcp-project"
      DeploymentTimeout: "10m"
      NamespaceTimeout: "2m"
      MaxCPU: "8"
      MaxMemory: "8Gi"
      QueueResourcePercentage: "20"
      IsPredictionJobEnabled: true
      IsDefaultPredictionJob: true
      DefaultPredictionJobConfig:
        ExecutorReplica: 3
        DriverCPURequest: "2"
        DriverMemoryRequest: "2Gi"
        ExecutorCPURequest: "2"
        ExecutorMemoryRequest: "2Gi"
      DefaultDeploymentConfig:
        MinReplica: 0
        MaxReplica: 1
        CPURequest: "500m"
        MemoryRequest: "500Mi"
      DefaultTransformerConfig:
        MinReplica: 0
        MaxReplica: 1
        CPURequest: "500m"
        MemoryRequest: "500Mi"
      K8sConfig:
      # Example k8s_config to connect to cluster using gke-gcloud-auth-plugin
      # name: dev-cluster
      # cluster:
      #   server: https://k8s.cluster
      #   certificate-authority-data: some_cert_data
      # user:
      #   exec:
      #     apiVersion: client.authentication.k8s.io/v1beta1
      #     args: ["--use_application_default_credentials"]
      #     command: gke-gcloud-auth-plugin
      #     interactiveMode: IfAvailable
      #     provideClusterInfo: true

imageBuilder:
  serviceAccount:
    create: true
    name: "kaniko"
    annotations: {}
    labels: {}

# Google service account used to access GCP's resources.
#
# gcpServiceAccount:
#   secretName: merlin-secret
#   secretKey: service-account.json
encryption:
  key: "password"
ui:
  oauthClientID: ""
  homepage: /merlin
  apiHost: /api/merlin/v1
  upiDocURL: "https://github.com/caraml-dev/universal-prediction-interface/blob/main/docs/api_markdown/caraml/upi/v1/index.md"
  mlp:
    apiHost: /api
  docsURL:
    [
      {
        "href": "https://github.com/gojek/merlin/blob/main/docs/getting-started/README.md",
        "label": "Getting Started with Merlin",
      },
    ]
  # -- Comma-separated value of Docker registries that can be chosen in deployment page
  dockerRegistries: ghcr.io/gojek,ghcr.io/your-company
  maxAllowedReplica: 20
service:
  externalPort: 8080
  internalPort: 8080
serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name: merlin
  annotations: {}
  # example.io/example: example
ingress:
  enabled: false
# If you would like to use an external postgres database for Merlin, you can connect using these credentials
merlinExternalPostgresql:
  # -- If you would like to use an external postgres database, enable it here using this
  enabled: false
  # -- External postgres database user
  username: merlin
  # -- External postgres database schema
  database: merlin
  # -- Set the External postgres db password using this value at runtime (using --set flag) to create a secret
  password: password
  # -- Host address for the External postgres
  address: 127.0.0.1
  # -- Enable this if you need the chart to create a secret when you provide the password above.
  createSecret: false
  # -- If a secret is created by external systems (eg. Vault)., mention the secret name here
  secretName: ""
  # -- If a secret is created by external systems (eg. Vault)., mention the key under which password is stored in secret (eg. postgresql-password)
  secretKey: ""
  # -- Connection pooling settings
  connMaxIdleTime: 0s
  connMaxLifetime: 0s
  maxIdleConns: 0
  maxOpenConns: 0
  # -- Enable if you want to configure a sidecar for creating a proxy for your db connections.
  enableProxySidecar: false
  # -- Type of sidecar to be created, mentioned type needs to have the spec below.
  proxyType: cloudSqlProxy
  # -- container spec for the sidecar
  sidecarSpec:
    # -- container spec for the Google CloudSQL auth proxy sidecar, ref: https://cloud.google.com/sql/docs/postgres/connect-kubernetes-engine
    cloudSqlProxy:
      dbConnectionName: "asia-east-1:merlin-db"
      dbPort: 5432
      image:
        tag: 1.33.2
      resources: &merlinCloudCarSpecResource
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1G
      # -- Container spec for the sidecar
      spec:
        - name: cloud-sql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:{{ .Values.merlinExternalPostgresql.sidecarSpec.cloudSqlProxy.image.tag }}
          command:
            - "/cloud_sql_proxy"
            - "-ip_address_types=PRIVATE"
            - "-log_debug_stdout"
            - "-instances={{ .Values.merlinExternalPostgresql.sidecarSpec.cloudSqlProxy.dbConnectionName }}=tcp:{{ .Values.merlinExternalPostgresql.sidecarSpec.cloudSqlProxy.dbPort }}"
          securityContext:
            runAsNonRoot: true
          resources: *merlinCloudCarSpecResource
merlin-postgresql:
  enabled: true
  postgresqlUsername: merlin
  postgresqlDatabase: merlin
  # -- By default postgres will generate a password, if you wish to choose the password, secret will be created using this password, must be specified using --set flag.
  # postgresqlPassword: merlin
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
  # metrics:
  #   enabled: true
  #   serviceMonitor:
  #     enabled: false
  # replication:
  #   enabled: false
  #   user: repl_user
  #   password: repl_password
  #   slaveReplicas: 2
  #   Set synchronous commit mode: on, off, remote_apply, remote_write and local
  #   ref: https://www.postgresql.org/docs/9.6/runtime-config-wal.html#GUC-WAL-LEVEL
  #   synchronousCommit: "on"
  #   From the number of `slaveReplicas` defined above, set the number of those that will have synchronous replication
  #   NOTE: It cannot be > slaveReplicas
  #   numSynchronousReplicas: 2
  #   Replication Cluster application name. Useful for defining multiple replication policies
  #   applicationName: merlin
  persistence:
    size: 10Gi
mlp:
  enabled: true
  environmentConfigSecret:
    name: ""
mlflow:
  # This should be the actual DNS registered
  trackingURL: "http://www.example.com"
  # Type of artifact service storage
  artifactServiceType: nop
  ## mlflow container name
  ##
  name: mlflow
  # Additional labels to apply to the mlflow deployment
  deploymentLabels: {}
  # Additional labels to apply to the mlflow pods
  podLabels: {}
  image:
    registry: ghcr.io
    repository: gojek/mlflow
    tag: 1.3.0
    pullPolicy: Always
  replicaCount: 1
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 0
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      memory: "2048Mi"
  # expects input structure as per specification https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#toleration-v1-core
  # for example:
  #   tolerations:
  #   - key: foo.bar.com/role
  #     operator: Equal
  #     value: master
  #     effect: NoSchedule
  tolerations: []
  ## The backend store is where MLflow server stores experiment
  ## and run metadata as well as params, metrics, and tags for runs.
  ## MLflow supports two types of backend stores: file store and database-backed store.
  #
  # backendStoreUri: "/data/mlruns"

  ## Local or GCS URI to store artifacts in, for
  ## newly created experiments. Note that this flag
  ## does not impact already-created experiments.
  #
  artifactRoot: "/data/artifacts"
  ## Use this field to add environment variables relevant to MLflow server.
  ## These fields will be passed on to MLflow container(s) when Chart is deployed.
  #
  # extraEnvs:
  #   FOO: bar

  ## The network address to listen on (default:
  ## 127.0.0.1). Use 0.0.0.0 to bind to all
  ## addresses if you want to access the tracking
  ## server from other machines.
  #
  host: "0.0.0.0"
  ## Update strategy, can be set to RollingUpdate or onDelete by default.
  ## https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#updating-statefulsets
  #
  statefulset:
    updateStrategy: RollingUpdate
  service:
    type: ClusterIP
    externalPort: 80
    internalPort: 5000
  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name: mlflow
    annotations: {}
    # example.io/example: example
  ingress:
    enabled: false
    class: "nginx"
    # host:
  # These labels help us to account for the usage and cost of each deployment used in all environments and also the teams using them.
  # For the `app` label, there will be problems relabelling them since the replication controller uses the old values.
  # Feel free to put other podLabels as you deem fit.
  #
  # podLabels:
  #   environment: unknown
  #   team: unknown
  #   stream: unknown
  #   orchestrator: unknown

  # Add the following configs when you wish to point to an actual S3 for mlflow to store its artifacts
  extraEnvs: {}
  #   AWS_ACCESS_KEY_ID: YOURACCESSKEY
  #   AWS_SECRET_ACCESS_KEY: YOURSECRETKEY
  #   AWS_DEFAULT_REGION: ap-southeast-2
  #   Instead of this env variable minio.enabled should be used:
  #   MLFLOW_S3_ENDPOINT_URL: http://minio.minio.svc.cluster.local:9000
# If you would like to use an external postgres database for MLflow, you can connect using these credentials
mlflowExternalPostgresql:
  # -- If you would like to use an external postgres database, enable it here using this
  enabled: false
  # -- External postgres database user
  username: mlflow
  # -- External postgres database schema
  database: mlflow
  # -- Set the External postgres db password using this value at runtime (using --set flag) to create a secret
  password: password
  # -- Host address for the External postgres
  address: 127.0.0.1
  # -- Enable this if you need the chart to create a secret when you provide the password above.
  createSecret: false
  # -- If a secret is created by external systems (eg. Vault)., mention the secret name here
  secretName: ""
  # -- If a secret is created by external systems (eg. Vault)., mention the key under which password is stored in secret (eg. postgresql-password)
  secretKey: ""
  # -- Enable if you want to configure a sidecar for creating a proxy for your db connections.
  enableProxySidecar: false
  # -- Type of sidecar to be created, mentioned type needs to have the spec below.
  proxyType: cloudSqlProxy
  # -- container spec for the sidecar
  sidecarSpec:
    # -- container spec for the Google CloudSQL auth proxy sidecar, ref: https://cloud.google.com/sql/docs/postgres/connect-kubernetes-engine
    cloudSqlProxy:
      dbConnectionName: "asia-east-1:mlflow-db"
      dbPort: 5432
      image:
        tag: 1.33.2
      resources: &mlflowCloudSideCarSpecResource
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1G
      # -- Container spec for the sidecar
      spec:
        - name: cloud-sql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:{{ .Values.mlflowExternalPostgresql.sidecarSpec.cloudSqlProxy.image.tag }}
          command:
            - "/cloud_sql_proxy"
            - "-ip_address_types=PRIVATE"
            - "-log_debug_stdout"
            - "-instances={{ .Values.mlflowExternalPostgresql.sidecarSpec.cloudSqlProxy.dbConnectionName }}=tcp:{{ .Values.mlflowExternalPostgresql.sidecarSpec.cloudSqlProxy.dbPort }}"
          securityContext:
            runAsNonRoot: true
          resources: *mlflowCloudSideCarSpecResource
mlflow-postgresql:
  enabled: true
  postgresqlUsername: mlflow
  postgresqlDatabase: mlflow
  # -- By default postgres will generate a password, if you wish to choose the password, secret will be created using this password, must be specified using --set flag.
  # postgresqlPassword: mlflow

  replicaCount: 1
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
  persistence:
    enabled: true
    size: 10Gi
swagger:
  enabled: true
  image:
    tag: v3.23.5
  apiHost: "merlin.dev"
  basePath: "/api/merlin/v1"
  service:
    internalPort: 8081
    externalPort: 8080
minio:
  enabled: true
  hook:
    weight: "-2"
  helmChart:
    chart: minio
    repository: "https://helm.min.io/"
    version: 7.0.4
    release: minio
    namespace: minio
    createNamespace: true
  chartValues:
    replicas: 1
    persistence:
      enabled: false
    resources:
      requests:
        cpu: 25m
        memory: 64Mi
    livenessProbe:
      initialDelaySeconds: 30
    defaultBucket:
      enabled: true
      name: mlflow
    ingress:
      enabled: false
      annotations:
        kubernetes.io/ingress.class: istio
      path: /*
kserve:
  enabled: true
  hook:
    weight: "-2"
  helmChart:
    chart: kserve
    repository: "https://caraml-dev.github.io/helm-charts"
    version: 0.8.22
    release: kserve
    namespace: kserve
    createNamespace: true
  chartValues:
    knativeServingIstio:
      chartValues:
        istioIngressGateway:
          helmChart:
            namespace: "istio-system"
