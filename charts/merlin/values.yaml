global:
  protocol: http
deployment:
  image:
    pullPolicy: IfNotPresent
    registry: ghcr.io
    repository: caraml-dev/merlin
    tag: 0.27.0-rc1
  replicaCount: "2"
  # Additional labels to apply to the deployment
  labels: {}
  # Additional labels to apply to the merlin pods
  podLabels: {}
  resources:
    requests:
      cpu: "500m"
      memory: 1Gi
    limits:
      cpu: "1"
      memory: 1Gi
  # expects input structure as per specification https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#toleration-v1-core
  # for example:
  #   tolerations:
  #   - key: foo.bar.com/role
  #     operator: Equal
  #     value: master
  #     effect: NoSchedule
  tolerations: []
environment: dev
deploymentLabelPrefix: "gojek.com/"
pyfuncGRPCOptions: "{}"
loggerDestinationURL: "http://yourDestinationLogger"
queue:
  numOfWorkers: 1
mlpApi:
  apiHost: http://mlp.mlp:8080/v1
  # encryptionKey must be specified using --set flag.
  encryptionKey: secret-encryption
feastCoreApi:
  apiHost: http://feast-core.mlp:8080/v1
imageBuilder:
  serviceAccount:
    create: true
    name: "kaniko"
    annotations: {}
    labels: {}
  clusterName: "test"
  baseImages:
    3.7.*:
      imageName: pyfunc-py37:v0.1.0
      dockerfilePath: "docker/Dockerfile"
      buildContextURI: "git://github.com/gojek/merlin.git#refs/tags/v0.1"
      mainAppPath: /merlin-spark-app/main.py
  predictionJobBaseImages:
    3.7.*:
      imageName: pyspark-py37:v0.1.0
      dockerfilePath: "docker/app.Dockerfile"
      buildContextURI: "git://github.com/gojek/merlin.git#refs/tags/v0.1"
      mainAppPath: /merlin-spark-app/main.py
  predictionJobContextSubPath: ""
  namespace: "mlp"
  dockerRegistry: "dockerRegistry"
  timeout: "30m"
  retention: "48h"
  kanikoImage: "gcr.io/kaniko-project/executor:v1.6.0"
  resources:
    requests:
      cpu: "1"
      memory: 512Mi
    limits:
      cpu: "1"
      memory: 1Gi
  tolerations: []
  nodeSelectors: {}
  maxRetry: 3
  safeToEvict: false
  k8sConfig: ""
  # Example json
  # '{
  #   "name": "dev-cluster",
  #   "cluster": {
  #     "server": "https://k8s.cluster",
  #     "certificate-authority-data": "some_cert_data"
  #   },
  #   "user": {
  #     "exec": {
  #       "apiVersion": "client.authentication.k8s.io/v1beta1",
  #       "args": [
  #         "--use_application_default_credentials"
  #       ],
  #       "command": "gke-gcloud-auth-plugin",
  #       "interactiveMode": "IfAvailable",
  #       "provideClusterInfo": true
  #     }
  #   }
  # }'
alerts:
  # -- To enable/disable creation/modification of the alerts and dashboards for the deployed models via merlin.
  enabled: false
  # -- Repository platform where the created Alerts and Dashboards need to be pushed. Platforms supported as of now: Gitlab
  alertsRepoPlatform: gitlab
  baseURL: https://gitlab.com/
  # Access token must be specified using --set flag.
  # token:
  dashboardRepository: data-science/slo-specs
  dashboardBranch: master
  alertRepository: lens/artillery/datascience
  alertBranch: master
  warden:
    apiHost: ""
monitoring:
  enabled: false
  # baseURL: ""
  # jobBaseURL: ""
transformer:
  simulation:
    feastRedisServingURL: online-serving-redis.feast.dev
    feastBigtableServingURL: online-serving-bt.feast.dev
  feast:
    defaultServingURL: online-serving-redis.feast.dev
    servingURLs:
      [
        {
          host: "online-serving-redis.feast.dev",
          label: "Online Serving with Redis",
          source_type: "REDIS",
          icon: "redis",
        },
        {
          host: "online-serving-bigtable.feast.dev",
          label: "Online Serving with BigTable",
          source_type: "BIGTABLE",
          icon: "bigtable",
        },
      ]
    ## Redis storage configuration for feast retrieval
    ##
    # redisStorage:
    #   is_using_direct_storage: false
    #   is_redis_cluster: true
    #   serving_url: "online-serving-redis.feast.dev"
    #   redis_addresses:
    #     - 10.1.1.2
    #     - 10.1.1.3
    #   pool_size: 5
    #   max_retries: 0
    #   read_timeout: "1s"
    #   write_timeout: "1s"
    #   min_idle_conn: 2

    ## Bigtable storage configuration for feast retrieval
    ##
    # bigtableStorage:
    #   serving_url: "online-serving-bigtable.feast.dev"
    #   is_using_direct_storage: false
    #   project: "gcp-project"
    #   instance: instance
    #   app_profile: default
    #   pool_size: 5
    #   keep_alive_interval: "2m"
    #   keep_alive_timeout: "1m"
    defaultFeastSource: BIGTABLE
    bigtableCredential:
    coreURL: core.feast.dev
    coreAuthAudience: core.feast.dev
    authEnabled: false
    grpc:
      keepAliveEnabled: false
      keepAliveTime: 60s
      keepAliveTimeout: 5s
  image: merlin-transformer:1.0.0
  jaeger:
    agentHost: localhost
    agentPort: 6831
    samplerType: const
    samplerParam: 1
    disabled: false
  model:
    grpc:
      keepAliveEnabled: false
      keepAliveTime: 60s
      keepAliveTimeout: 5s
  kafka:
    brokers: "kafka-brokers"
    maxMessageSize: "1048588"

# Google service account used to access GCP's resources.
#
# gcpServiceAccount:
#   secretName: merlin-secret
#   secretKey: service-account.json
environmentConfigs:
  - name: "id-dev"
    is_default: true
    cluster: "test"
    region: "id"
    gcp_project: "gcp-project"
    deployment_timeout: "10m"
    namespace_timeout: "2m"
    max_cpu: "8"
    max_memory: "8Gi"
    queue_resource_percentage: "20"
    is_prediction_job_enabled: true
    is_default_prediction_job: true
    default_prediction_job_config:
      executor_replica: 3
      driver_cpu_request: "2"
      driver_memory_request: "2Gi"
      executor_cpu_request: "2"
      executor_memory_request: "2Gi"
    default_deployment_config:
      min_replica: 0
      max_replica: 1
      cpu_request: "500m"
      memory_request: "500Mi"
    default_transformer_config:
      min_replica: 0
      max_replica: 1
      cpu_request: "500m"
      memory_request: "500Mi"
    k8s_config: {}
    # Example k8s_config to connect to cluster using gke-gcloud-auth-plugin
    # name: dev-cluster
    # cluster:
    #   server: https://k8s.cluster
    #   certificate-authority-data: some_cert_data
    # user:
    #   exec:
    #     apiVersion: client.authentication.k8s.io/v1beta1
    #     args: ["--use_application_default_credentials"]
    #     command: gke-gcloud-auth-plugin
    #     interactiveMode: IfAvailable
    #     provideClusterInfo: true
sentry:
  enabled: false
  dsn: ""
newrelic:
  enabled: false
  appname: "merlin-api-dev"
  licenseSecretName: "newrelic-license-secret"
authorization:
  enabled: true
  serverUrl: http://mlp-authorization-keto
encryption:
  key: "password"
ui:
  oauthClientID: ""
  homepage: /merlin
  apiHost: /api/merlin/v1
  upiDocURL: "https://github.com/caraml-dev/universal-prediction-interface/blob/main/docs/api_markdown/caraml/upi/v1/index.md"
  mlp:
    apiHost: /api/v1
  docsURL:
    [
      {
        "href": "https://github.com/gojek/merlin/blob/main/docs/getting-started/README.md",
        "label": "Getting Started with Merlin",
      },
    ]
  # -- Comma-separated value of Docker registries that can be chosen in deployment page
  dockerRegistries: ghcr.io/gojek,ghcr.io/your-company
  maxAllowedReplica: 20
service:
  externalPort: 8080
  internalPort: 8080
serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name: merlin
  annotations: {}
  # example.io/example: example
ingress:
  enabled: false
# If you would like to use an external postgres database for Merlin, you can connect using these credentials
merlinExternalPostgresql:
  # -- If you would like to use an external postgres database, enable it here using this
  enabled: false
  # -- External postgres database user
  username: merlin
  # -- External postgres database schema
  database: merlin
  # -- Set the External postgres db password using this value at runtime (using --set flag) to create a secret
  password: password
  # -- Host address for the External postgres
  address: 127.0.0.1
  # -- Enable this if you need the chart to create a secret when you provide the password above.
  createSecret: false
  # -- If a secret is created by external systems (eg. Vault)., mention the secret name here
  secretName: ""
  # -- If a secret is created by external systems (eg. Vault)., mention the key under which password is stored in secret (eg. postgresql-password)
  secretKey: ""
  # -- Connection pooling settings
  connMaxIdleTime: 0s
  connMaxLifetime: 0s
  maxIdleConns: 0
  maxOpenConns: 0
  # -- Enable if you want to configure a sidecar for creating a proxy for your db connections.
  enableProxySidecar: false
  # -- Type of sidecar to be created, mentioned type needs to have the spec below.
  proxyType: cloudSqlProxy
  # -- container spec for the sidecar
  sidecarSpec:
    # -- container spec for the Google CloudSQL auth proxy sidecar, ref: https://cloud.google.com/sql/docs/postgres/connect-kubernetes-engine
    cloudSqlProxy:
      dbConnectionName: "asia-east-1:merlin-db"
      dbPort: 5432
      image:
        tag: 1.33.2
      resources: &merlinCloudCarSpecResource
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1G
      # -- Container spec for the sidecar
      spec:
        - name: cloud-sql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:{{ .Values.merlinExternalPostgresql.sidecarSpec.cloudSqlProxy.image.tag }}
          command:
            - "/cloud_sql_proxy"
            - "-ip_address_types=PRIVATE"
            - "-log_debug_stdout"
            - "-instances={{ .Values.merlinExternalPostgresql.sidecarSpec.cloudSqlProxy.dbConnectionName }}=tcp:{{ .Values.merlinExternalPostgresql.sidecarSpec.cloudSqlProxy.dbPort }}"
          securityContext:
            runAsNonRoot: true
          resources: *merlinCloudCarSpecResource
merlin-postgresql:
  enabled: true
  postgresqlUsername: merlin
  postgresqlDatabase: merlin
  # -- By default postgres will generate a password, if you wish to choose the password, secret will be created using this password, must be specified using --set flag.
  # postgresqlPassword: merlin

  resources:
    requests:
      cpu: 100m
      memory: 512Mi
  # metrics:
  #   enabled: true
  #   serviceMonitor:
  #     enabled: false
  # replication:
  #   enabled: false
  #   user: repl_user
  #   password: repl_password
  #   slaveReplicas: 2
  #   Set synchronous commit mode: on, off, remote_apply, remote_write and local
  #   ref: https://www.postgresql.org/docs/9.6/runtime-config-wal.html#GUC-WAL-LEVEL
  #   synchronousCommit: "on"
  #   From the number of `slaveReplicas` defined above, set the number of those that will have synchronous replication
  #   NOTE: It cannot be > slaveReplicas
  #   numSynchronousReplicas: 2
  #   Replication Cluster application name. Useful for defining multiple replication policies
  #   applicationName: merlin
  persistence:
    size: 10Gi
mlp:
  enabled: true
  environmentConfigSecret:
    name: ""
mlflow:
  # This should be the actual DNS registered
  trackingURL: "http://www.example.com"
  ## mlflow container name
  ##
  name: mlflow
  # Additional labels to apply to the mlflow deployment
  deploymentLabels: {}
  # Additional labels to apply to the mlflow pods
  podLabels: {}
  image:
    registry: ghcr.io
    repository: gojek/mlflow
    tag: 1.3.0
    pullPolicy: Always
  replicaCount: 1
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 0
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      memory: "2048Mi"
  # expects input structure as per specification https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#toleration-v1-core
  # for example:
  #   tolerations:
  #   - key: foo.bar.com/role
  #     operator: Equal
  #     value: master
  #     effect: NoSchedule
  tolerations: []
  ## The backend store is where MLflow server stores experiment
  ## and run metadata as well as params, metrics, and tags for runs.
  ## MLflow supports two types of backend stores: file store and database-backed store.
  #
  # backendStoreUri: "/data/mlruns"

  ## Local or GCS URI to store artifacts in, for
  ## newly created experiments. Note that this flag
  ## does not impact already-created experiments.
  #
  artifactRoot: "/data/artifacts"
  ## Use this field to add environment variables relevant to MLflow server.
  ## These fields will be passed on to MLflow container(s) when Chart is deployed.
  #
  # extraEnvs:
  #   FOO: bar

  ## The network address to listen on (default:
  ## 127.0.0.1). Use 0.0.0.0 to bind to all
  ## addresses if you want to access the tracking
  ## server from other machines.
  #
  host: "0.0.0.0"
  ## Update strategy, can be set to RollingUpdate or onDelete by default.
  ## https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#updating-statefulsets
  #
  statefulset:
    updateStrategy: RollingUpdate
  service:
    type: ClusterIP
    externalPort: 80
    internalPort: 5000
  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name: mlflow
    annotations:
      {}
      # example.io/example: example
  ingress:
    enabled: false
    class: "nginx"
    # host:
  # These labels help us to account for the usage and cost of each deployment used in all environments and also the teams using them.
  # For the `app` label, there will be problems relabelling them since the replication controller uses the old values.
  # Feel free to put other podLabels as you deem fit.
  #
  # podLabels:
  #   environment: unknown
  #   team: unknown
  #   stream: unknown
  #   orchestrator: unknown

  # Add the following configs when you wish to point to an actual S3 for mlflow to store its artifacts
  extraEnvs: {}
  #   AWS_ACCESS_KEY_ID: YOURACCESSKEY
  #   AWS_SECRET_ACCESS_KEY: YOURSECRETKEY
  #   AWS_DEFAULT_REGION: ap-southeast-2
  #   Instead of this env variable minio.enabled should be used:
  #   MLFLOW_S3_ENDPOINT_URL: http://minio.minio.svc.cluster.local:9000
# If you would like to use an external postgres database for MLflow, you can connect using these credentials
mlflowExternalPostgresql:
  # -- If you would like to use an external postgres database, enable it here using this
  enabled: false
  # -- External postgres database user
  username: mlflow
  # -- External postgres database schema
  database: mlflow
  # -- Set the External postgres db password using this value at runtime (using --set flag) to create a secret
  password: password
  # -- Host address for the External postgres
  address: 127.0.0.1
  # -- Enable this if you need the chart to create a secret when you provide the password above.
  createSecret: false
  # -- If a secret is created by external systems (eg. Vault)., mention the secret name here
  secretName: ""
  # -- If a secret is created by external systems (eg. Vault)., mention the key under which password is stored in secret (eg. postgresql-password)
  secretKey: ""
  # -- Enable if you want to configure a sidecar for creating a proxy for your db connections.
  enableProxySidecar: false
  # -- Type of sidecar to be created, mentioned type needs to have the spec below.
  proxyType: cloudSqlProxy
  # -- container spec for the sidecar
  sidecarSpec:
    # -- container spec for the Google CloudSQL auth proxy sidecar, ref: https://cloud.google.com/sql/docs/postgres/connect-kubernetes-engine
    cloudSqlProxy:
      dbConnectionName: "asia-east-1:mlflow-db"
      dbPort: 5432
      image:
        tag: 1.33.2
      resources: &mlflowCloudSideCarSpecResource
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1G
      # -- Container spec for the sidecar
      spec:
        - name: cloud-sql-proxy
          image: gcr.io/cloudsql-docker/gce-proxy:{{ .Values.mlflowExternalPostgresql.sidecarSpec.cloudSqlProxy.image.tag }}
          command:
            - "/cloud_sql_proxy"
            - "-ip_address_types=PRIVATE"
            - "-log_debug_stdout"
            - "-instances={{ .Values.mlflowExternalPostgresql.sidecarSpec.cloudSqlProxy.dbConnectionName }}=tcp:{{ .Values.mlflowExternalPostgresql.sidecarSpec.cloudSqlProxy.dbPort }}"
          securityContext:
            runAsNonRoot: true
          resources: *mlflowCloudSideCarSpecResource
mlflow-postgresql:
  enabled: true
  postgresqlUsername: mlflow
  postgresqlDatabase: mlflow
  # -- By default postgres will generate a password, if you wish to choose the password, secret will be created using this password, must be specified using --set flag.
  # postgresqlPassword: mlflow

  replicaCount: 1
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
  persistence:
    enabled: true
    size: 10Gi
swagger:
  enabled: true
  image:
    tag: v3.23.5
  apiHost: "merlin.dev"
  basePath: "/api/merlin/v1"
  service:
    internalPort: 8081
    externalPort: 8080
minio:
  enabled: true
  hook:
    weight: "-2"
  helmChart:
    chart: minio
    repository: "https://helm.min.io/"
    version: 7.0.4
    release: minio
    namespace: minio
    createNamespace: true
  chartValues:
    replicas: 1
    persistence:
      enabled: false
    resources:
      requests:
        cpu: 25m
        memory: 64Mi
    livenessProbe:
      initialDelaySeconds: 30
    defaultBucket:
      enabled: true
      name: mlflow
    ingress:
      enabled: false
      annotations:
        kubernetes.io/ingress.class: istio
      path: /*
kserve:
  enabled: true
  hook:
    weight: "-2"
  helmChart:
    chart: kserve
    repository: "https://caraml-dev.github.io/helm-charts"
    version: 0.8.20
    release: kserve
    namespace: kserve
    createNamespace: true
  chartValues:
    knativeServingIstio:
      chartValues:
        istioIngressGateway:
          helmChart:
            namespace: "istio-system"
